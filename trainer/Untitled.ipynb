{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaaaa093-e94d-4956-b406-acf37f19fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile task.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import argparse\n",
    "import hypertune\n",
    "import os\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def get_args():\n",
    "  '''Parses args. Must include all hyperparameters you want to tune.'''\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      required=True,\n",
    "      type=float,\n",
    "      help='learning rate')\n",
    "  parser.add_argument(\n",
    "      '--momentum',\n",
    "      required=True,\n",
    "      type=float,\n",
    "      help='SGD momentum value')\n",
    "  parser.add_argument(\n",
    "      '--num_units',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='number of units in last hidden layer')\n",
    "  args = parser.parse_args()\n",
    "  return args\n",
    "\n",
    "def preprocess_data(image, label):\n",
    "  '''Resizes and scales images.'''\n",
    "\n",
    "  image = tf.image.resize(image, (150,150))\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "  '''Loads Horses Or Humans dataset and preprocesses data.'''\n",
    "\n",
    "  data, info = tfds.load(name='horses_or_humans', as_supervised=True, with_info=True)\n",
    "\n",
    "  # Create train dataset\n",
    "  train_data = data['train'].map(preprocess_data)\n",
    "  train_data  = train_data.shuffle(1000)\n",
    "  train_data  = train_data.batch(batch_size)\n",
    "\n",
    "  # Create validation dataset\n",
    "  validation_data = data['test'].map(preprocess_data)\n",
    "  validation_data  = validation_data.batch(batch_size)\n",
    "\n",
    "  return train_data, validation_data\n",
    "\n",
    "def create_model(num_units, learning_rate, momentum):\n",
    "  '''Defines and compiles model.'''\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "  x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(num_units, activation='relu')(x)\n",
    "  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def main():\n",
    "  args = get_args()\n",
    "\n",
    "  # Create distribution strategy\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "  # Get data\n",
    "  GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "  train_data, validation_data = create_dataset(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "  # Wrap variable creation within strategy scope\n",
    "  with strategy.scope():\n",
    "    model = create_model(args.num_units, args.learning_rate, args.momentum)\n",
    "\n",
    "  # Train model\n",
    "  history = model.fit(train_data, epochs=NUM_EPOCHS, validation_data=validation_data)\n",
    "\n",
    "  # Define metric\n",
    "  hp_metric = history.history['val_accuracy'][-1]\n",
    "\n",
    "  hpt = hypertune.HyperTune()\n",
    "  hpt.report_hyperparameter_tuning_metric(\n",
    "      hyperparameter_metric_tag='accuracy',\n",
    "      metric_value=hp_metric,\n",
    "      global_step=NUM_EPOCHS)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef41befe-f3a4-4271-8ed8-ad9bd728581d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25bf1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8067e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e1732d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42b101b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74591fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8e6bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --learning_rate LEARNING_RATE --momentum\n",
      "                             MOMENTUM --num_units NUM_UNITS\n",
      "ipykernel_launcher.py: error: the following arguments are required: --learning_rate, --momentum, --num_units\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avnish/ineuron/hyper_parameter_tuning/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4caf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "463910ce146bed12303e172b284c00e8e22ee69d30cebe72f21d2cf079fee307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
